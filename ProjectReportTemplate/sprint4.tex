
\subsection{Sprint No.~4}

\subsubsection*{Sprint Planning}

Goal: Rework apriori algorithm and display its results and implement evolution of classes' unittest comparison (additional usage scenario)

The goal of Sprint 4 was to rework the current apriori algorithm approach, finish it by adding the functionality for the strong rule generation and finally display it's results in our GUI.
Additionally, our first bonus usage scenario, which we suggested in Sprint 1, had to be implemented.

In order to improve our internal documentation and to address the goal of the sprint, we split the previous association analysis user story into two new, smaller ones. The first for the apriori algorithm implementation and the second for displaying it's results. We also started to assign more tasks to our user stories than before and introduced a general category for tasks that could be done if time allowed, mostly related to polishing the software or fixing minor bugs. These were mostly too small or unimportant to address them in an own user story.

\begin{itemize}
	\item User Story 23: Implement Apriori Algorithm (Prio 1 / Size L)
	\end{itemize}
As a developer,
I want to implement the apriori algorithm
so that I can generate the frequent item sets and the strong rules of loaded test runs
\begin{table}[h]
  \caption{User Story 23 Tasks}
  \label{Story 23 Tasks}
  \centering
  \begin{tabular}{p{1cm}|p{5cm}|p{3cm}|}
  	Nr & Description & Assigned \\ 
  	\hline
  	23.1 & Get failed classes of one test run & Tobias Schwartz, Jan Martin \\ 
  	\hline
  	23.2 & Generate frequent item sets & Tobias Schwartz \\ 
  	\hline
  	23.3 & Filter for class distances & Jan Martin \\ 
  	\hline
  	23.4 & Generate strong rules & Tobias Schwartz \\ 
  	\hline
  \end{tabular}
\end{table}

\newpage
\begin{itemize}
	\item User Story 24: Display Analysis Data (Prio 2 / Size M)
	\end{itemize}
As a user,
I want to view the results of the apriori algorithm in a graphically enriched view
so that I immediately see the dependencies between failed classes.
\begin{table}[h]
  \caption{User Story 24 Tasks}
  \label{Story 24 Tasks}
  \centering
  \begin{tabular}{p{1cm}|p{5cm}|p{3cm}|}
  	Nr & Description & Assigned \\ 
  	\hline
  	24.1 & sketch mockup of display & Tobias Schwartz \\ 
  	\hline
  	24.2 & implement mockup as a layout in JavaFx & Tobias Schwartz \\ 
  	\hline
  	24.3 & fill apriori display with calculated data & Tobias Schwartz \\ 
  	\hline
  \end{tabular}
\end{table}

\begin{itemize}
	\item User Story 213: Evolution of a class (additional usage scenario) (Prio 1 / Size L)
	\end{itemize}
As a user,
I want to see the differences in Unittests of a specific class in two selected test runs
so that I know what changed (improvement/deterioration).
\begin{table}[h]
  \caption{User Story 213 Tasks}
  \label{Story 213 Tasks}
  \centering
  \begin{tabular}{p{1cm}|p{5cm}|p{3cm}|}
  	Nr & Description & Assigned \\ 
  	\hline
  	213.1 & Mockup of additional usage scenario "evolution of a class" & Simon Meyer \\ 
  	\hline
  	213.2* & Change all doubleclicks to singleclicks & Frank Kessler \\ 
  	\hline
  	213.3 & Hover chart node for short infos (incl. timestamp) & Frank Kessler \\ 
  	\hline
  	213.4 & Chart in own Window & Frank Kessler \\ 
  	\hline
  	213.5 & Calculate failure percentage of one class between two testruns & Frank Kessler \\ 
  	\hline
  	213.6 & implement comparison layout according to previous mockup and feedback & Simon Meyer \\ 
  	\hline
  	213.7 & integrate comparison view (additional usage scenario) into chart tab window & Frank Kessler \\ 
  	\hline
  	213.8 & fill comparison/"evolution of a class" view with data & Frank Kessler \\ 
  	\hline
  \end{tabular}
\end{table}

\begin{itemize}
	\item General Tasks (No User Story)
	\end{itemize}

\begin{table}[h]
  \caption{General Tasks}
  \label{General Tasks}
  \centering
  \begin{tabular}{p{1cm}|p{5cm}|p{3cm}|}
  	Nr & Description & Assigned \\ 
  	\hline
  	(Gen) & clear data: clear testrunsummary as well & --- \\ 
  	\hline
  	(Gen) & change tableview highlighting (background, textcolour) & --- \\ 
  	\hline
  	(Gen) & hide classes with 0 failure percentage & --- \\ 
  	\hline
  	(Gen) & Update UseCase- and Scope-of-Workarea Diagrams & Andreas Köllner \\ 
  	\hline
  	(Gen) & digitalize paper-mockups & Andreas Köllner \\ 
  	\hline
  \end{tabular}
\end{table}


\subsubsection*{Noteworthy Development Aspects}

Apart from all previous expectations, the implementation of the Apriori algorithm consumed way more time than expected. Not only did we have to rewrite this whole portion, we also had to do some more detailed background reading to refine our knowledge about the different aspects of the algorithm. Since it seemed inefficient to make all group members read into this subject on a deeper level, it was hard to verify and discuss the results properly in the group. Similarly, the design of the algorithm's output in the GUI was mainly determined by the developers of said procedure.

Due to illness we had to cope with huge team member absence during this sprint. Also during the winter break many team members were unavailable and therefore the project did not continue with the pace we planned.

This resulted in delayed work, mostly in the graphical aspects of the program. In particular, the display of the Apriori algorithm's output was not finished by the end of the sprint. Also user story \ref{evolution213} was only done partially. From user story \#213, tasks 213.5 - 213.8 were left uncompleted. 

To summarize, in this sprint a mockup for the additional usage scenario has been created and translated into our GUI. Other than that, the only progress has been achieved in the Apriori algorithm development.

\subsubsection*{Sprint Review}

As already mentioned, we had acute problems with team member illness and winter break unavailability. This resulted in a less effective sprint. In fact, no user story was fully completed and therefore obviously the sprint goal was not achieved.
We still managed to finally finish the apriori algorithm and considering the lack of manpower, had some major progress in developing our additional usage scenario.  

We were also able to present those improvements in the meeting with the client. Although it was hard to show all the implemented functionality due to lack of displaying all information properly in the GUI, we still were able to discuss the important features and get some valuable feedback. Especially design recommendations were highly appreciated.

Furthermore, we discussed that due to the impediments we encountered, we shall propose one more usage scenario but should not focus on its development.



